{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Question Generator for Contextual RAG\n",
                "\n",
                "This notebook generates realistic sample questions and answers based on your document content, which can be used to evaluate your RAG system."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 0. Prerequisites"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "%load_ext autoreload\n",
                "%autoreload 2\n",
                "\n",
                "# Install required packages\n",
                "%pip install ipywidgets python-dotenv tqdm\n",
                "\n",
                "# Import basic dependencies\n",
                "import os\n",
                "import sys\n",
                "import json\n",
                "import uuid\n",
                "import random\n",
                "from pathlib import Path\n",
                "from tqdm.notebook import tqdm\n",
                "\n",
                "# Create output directory\n",
                "os.makedirs(\"output\", exist_ok=True)\n",
                "\n",
                "# Load environment variables from .env file\n",
                "try:\n",
                "    from dotenv import load_dotenv\n",
                "    load_dotenv('.env')\n",
                "    print(\"Environment variables loaded from .env file\")\n",
                "except ImportError:\n",
                "    print(\"python-dotenv not installed, skipping .env loading\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 1. Setup File Information"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Define input file and chunking parameters\n",
                "input_file = \"data/bedrock-ug.pdf\"\n",
                "chunk_size = 1000\n",
                "start_page = 0\n",
                "end_page = -1  # -1 means process all pages\n",
                "\n",
                "# Extract document name from file path\n",
                "document_name = Path(input_file).resolve().stem\n",
                "print(f\"Document name: {document_name}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "try:\n",
                "    # Import required services and configuration\n",
                "    from libs.bedrock_service import BedrockService\n",
                "    from config import Config\n",
                "    \n",
                "    # Load configuration\n",
                "    config = Config.load()\n",
                "    \n",
                "    # Update config with environment variables if available\n",
                "    config.aws.region = os.environ.get(\"AWS_DEFAULT_REGION\", config.aws.region)\n",
                "    config.aws.profile = os.environ.get(\"AWS_PROFILE\", config.aws.profile)\n",
                "    config.bedrock.model_id = os.environ.get(\"BEDROCK_MODEL_ID\", config.bedrock.model_id)\n",
                "    config.bedrock.embed_model_id = os.environ.get(\"EMBED_MODEL_ID\", config.bedrock.embed_model_id)\n",
                "    \n",
                "    # Initialize Bedrock service\n",
                "    bedrock_service = BedrockService(\n",
                "        config.aws.region, \n",
                "        config.aws.profile, \n",
                "        config.bedrock.retries, \n",
                "        config.bedrock.embed_model_id, \n",
                "        config.bedrock.model_id, \n",
                "        config.model.max_tokens, \n",
                "        config.model.temperature, \n",
                "        config.model.top_p\n",
                "    )\n",
                "    \n",
                "    print(\"✅ Bedrock service initialized successfully\")\n",
                "    print(f\"Model ID: {config.bedrock.model_id}\")\n",
                "    \n",
                "except ImportError as e:\n",
                "    print(f\"❌ Error importing required modules: {str(e)}\")\n",
                "    print(\"Make sure all dependencies are installed and the paths are correct\")\n",
                "    sys.path.append('..')\n",
                "    print(\"Added parent directory to Python path. Try running the cell again.\")\n",
                "    raise\n",
                "except Exception as e:\n",
                "    print(f\"❌ Error initializing Bedrock service: {str(e)}\")\n",
                "    raise"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 2. Split Document into Chunks"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "try:\n",
                "    # Import DocumentParser from local library\n",
                "    from libs.document_parser import DocumentParser\n",
                "    \n",
                "    print(f\"Loading PDF from {input_file}...\")\n",
                "    print(f\"Pages: {start_page} to {'end' if end_page == -1 else end_page}\")\n",
                "    \n",
                "    # Load and split document\n",
                "    full_text = DocumentParser.load_pdf(input_file, start_page, end_page)\n",
                "    chunked_document = DocumentParser.split(full_text, chunk_size, -1)\n",
                "    chunks = chunked_document[0]['chunks']\n",
                "    \n",
                "    print(f\"✅ Document loaded and split into {len(chunks)} chunks\")\n",
                "    \n",
                "except ImportError:\n",
                "    print(\"Error importing DocumentParser. Make sure the libs directory is available.\")\n",
                "    print(\"You might need to add the parent directory to Python path:\")\n",
                "    sys.path.append('..')\n",
                "    # Try again with updated path\n",
                "    from libs.document_parser import DocumentParser\n",
                "    full_text = DocumentParser.load_pdf(input_file, start_page, end_page)\n",
                "    chunked_document = DocumentParser.split(full_text, chunk_size, -1)\n",
                "    chunks = chunked_document[0]['chunks']\n",
                "except Exception as e:\n",
                "    print(f\"❌ Error loading or chunking document: {str(e)}\")\n",
                "    raise"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 3. Build Prompt and Tool Config\n",
                "\n",
                "Define the system prompts for different types of question generation and the tool configuration."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# System prompts for different question types\n",
                "sys_template = {\n",
                "    \"complex\": \"\"\"\n",
                "        You are an expert at generating practical questions based on given documentation.\n",
                "        Your task is to generate complex, reasoning questions and answers.\n",
                "\n",
                "        Follow these rules:\n",
                "        1. Generate questions that reflect real user information needs related to the document's subject matter (e.g., technical docs : feature availability, implementation details)\n",
                "        2. Ensure questions are relevant, concise, preferably under 25 words, and fully answerable with the provided information\n",
                "        3. Focus on extracting key information that users are likely to seek, while avoiding narrow or less important questions.\n",
                "        4. When provided with code blocks, focus on understanding the overall functionality rather than the specific syntax or variables. Feel free to request examples of how to use key APIs or features.\n",
                "        5. Do not use phrases like 'based on the provided context' or 'according to the context'.\n",
                "    \"\"\",\n",
                "    \"simple\": \"\"\"\n",
                "        You are an expert at generating practical questions based on given documentation.\n",
                "        Your task is to create simple, directly answerable questions from the given context.\n",
                "\n",
                "        Follow these rules:\n",
                "        1. Generate questions that reflect real user information needs related to the document's subject matter (e.g., technical docs : feature availability, implementation details)\n",
                "        2. Ensure questions are relevant, concise, preferably under 10 words, and fully answerable with the provided information\n",
                "        3. Focus on extracting key information that users are likely to seek, while avoiding narrow or less important questions.\n",
                "        4. When provided with code blocks, focus on understanding the overall functionality rather than the specific syntax or variables. Feel free to request examples of how to use key APIs or features.\n",
                "        5. Do not use phrases like 'based on the provided context' or 'according to the context'.\n",
                "    \"\"\"\n",
                "}\n",
                "\n",
                "print(\"System prompts defined for simple and complex questions\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Tool configuration for question-answer generation\n",
                "tool_config = {\n",
                "    \"tools\": [\n",
                "        {\n",
                "            \"toolSpec\": {\n",
                "                \"name\": \"QuestionAnswerGenerator\",\n",
                "                \"description\": \"Generates questions and answers based on the given context.\",\n",
                "                \"inputSchema\": {\n",
                "                    \"json\": {\n",
                "                        \"type\": \"object\",\n",
                "                        \"properties\": {\n",
                "                            \"question\": {\n",
                "                                \"type\": \"string\",\n",
                "                                \"description\": \"The generated question\"\n",
                "                            },\n",
                "                            \"answer\": {\n",
                "                                \"type\": \"string\",\n",
                "                                \"description\": \"The answer to the generated question\"\n",
                "                            }\n",
                "                        },\n",
                "                        \"required\": [\"question\", \"answer\"]\n",
                "                    }\n",
                "                }\n",
                "            }\n",
                "        }\n",
                "    ]\n",
                "}\n",
                "\n",
                "print(\"Tool configuration defined for QuestionAnswerGenerator\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 4. Generate Questions"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Set the number of question-answer pairs to generate\n",
                "num_pairs = 5  # Will generate 5 simple and 5 complex questions (total 10)\n",
                "\n",
                "# Define output file path\n",
                "output_file = f\"output/{document_name}_sample_questions.jsonl\"\n",
                "print(f\"Questions will be saved to: {output_file}\")\n",
                "\n",
                "# Delete existing output file if it exists\n",
                "if os.path.exists(output_file):\n",
                "    os.remove(output_file)\n",
                "    print(f\"Removed existing file: {output_file}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Initialize dataset to store generated questions\n",
                "total_chunks = len(chunks)\n",
                "dataset = []\n",
                "\n",
                "# Track questions by type\n",
                "generated_question = {\"simple\": [], \"complex\": []}\n",
                "\n",
                "# Generation parameters\n",
                "temperature = 0.0\n",
                "top_p = 0.5\n",
                "\n",
                "# Validate that we have enough chunks\n",
                "if total_chunks < 3:\n",
                "    raise ValueError(f\"Not enough chunks to generate questions. Found {total_chunks}, need at least 3.\")\n",
                "\n",
                "print(f\"Generating {num_pairs*2} questions ({num_pairs} simple + {num_pairs} complex)...\")\n",
                "\n",
                "# Generate questions\n",
                "for i in tqdm(range(num_pairs * 2)):\n",
                "    try:\n",
                "        # Select random starting chunk position\n",
                "        start_id = random.randint(0, total_chunks - 3)\n",
                "        \n",
                "        # Get three consecutive chunks for context\n",
                "        context_chunks = [\n",
                "            chunks[start_id]['content'],\n",
                "            chunks[start_id + 1]['content'],\n",
                "            chunks[start_id + 2]['content']\n",
                "        ]\n",
                "        \n",
                "        # Combine chunks into context\n",
                "        context = \" \".join(context_chunks)\n",
                "        \n",
                "        # Alternate between complex and simple questions\n",
                "        if i % 2 == 0:\n",
                "            question_type = \"complex\"\n",
                "        else:\n",
                "            question_type = \"simple\"\n",
                "\n",
                "        # Create user prompt\n",
                "        user_template = f\"\"\"\n",
                "        Generate a {question_type} question and its answer based on the following context:\n",
                "\n",
                "        Context: {context}\n",
                "\n",
                "        Use the QuestionAnswerGenerator tool to provide the output.\n",
                "        \"\"\"\n",
                "\n",
                "        # Prepare prompt and inference config\n",
                "        sys_prompt = sys_template[question_type]\n",
                "        user_prompt = [{\"role\": \"user\", \"content\": [{\"text\": user_template}]}]\n",
                "\n",
                "        # Call Bedrock with tool configuration\n",
                "        response = bedrock_service.converse_with_tools(\n",
                "            messages=user_prompt,\n",
                "            system_prompt=sys_prompt,\n",
                "            tools=tool_config,\n",
                "            temperature=temperature,\n",
                "            top_p=top_p,\n",
                "            max_tokens=4096\n",
                "        )\n",
                "\n",
                "        stop_reason = response['stopReason']\n",
                "\n",
                "        # Process the tool response\n",
                "        if stop_reason == 'tool_use':\n",
                "            tool_requests = response['output']['message']['content']\n",
                "\n",
                "            for tool_request in [x for x in tool_requests if 'toolUse' in x]:\n",
                "                if tool_request['toolUse']['name'] == 'QuestionAnswerGenerator':\n",
                "                    # Extract question and answer\n",
                "                    question = tool_request['toolUse']['input']['question']\n",
                "                    answer = tool_request['toolUse']['input']['answer']\n",
                "                    \n",
                "                    # Create QA item\n",
                "                    qa_item = {\n",
                "                        \"question\": question,\n",
                "                        \"ground_truth\": answer,\n",
                "                        \"question_type\": question_type,\n",
                "                        \"context\": context\n",
                "                    }\n",
                "\n",
                "                    # Save to JSONL file\n",
                "                    with open(output_file, 'a') as f:\n",
                "                        json.dump(qa_item, f)\n",
                "                        f.write('\\n')\n",
                "                    \n",
                "                    # Add to dataset\n",
                "                    dataset.append(qa_item)\n",
                "                    generated_question[question_type].append(question)\n",
                "                    \n",
                "                    print(f\"Question {i+1}/{num_pairs*2} ({question_type}): {question[:50]}...\")\n",
                "        else:\n",
                "            print(f\"⚠️ Warning: Question generation stopped with reason '{stop_reason}' instead of 'tool_use'\")\n",
                "            \n",
                "    except Exception as e:\n",
                "        print(f\"❌ Error generating question {i+1}: {str(e)}\")\n",
                "\n",
                "print(f\"\\n✅ Generated {len(dataset)} questions ({len(generated_question['simple'])} simple + {len(generated_question['complex'])} complex)\")\n",
                "print(f\"Questions saved to {output_file}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 5. Display Sample Questions"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Display a sample of generated questions\n",
                "print(\"\\n=== Sample Simple Questions ===\")\n",
                "for i, question in enumerate(generated_question[\"simple\"][:3], 1):\n",
                "    print(f\"{i}. {question}\")\n",
                "\n",
                "print(\"\\n=== Sample Complex Questions ===\")\n",
                "for i, question in enumerate(generated_question[\"complex\"][:3], 1):\n",
                "    print(f\"{i}. {question}\")\n",
                "\n",
                "print(f\"\\n✅ Complete dataset saved to {output_file}\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "conda_python3",
            "language": "python",
            "name": "conda_python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.16"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
